

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>TensorFlow Lite &mdash; 简单粗暴TensorFlow 0.4 alpha 文档</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../../',
              VERSION:'0.4 alpha',
              LANGUAGE:'zh_CN',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/js/custom.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="TensorFlow in JavaScript" href="javascript.html" />
    <link rel="prev" title="TensorFlow Serving" href="serving.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> 简单粗暴TensorFlow
          

          
          </a>

          
            
            
              <div class="version">
                0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../preface.html">前言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">TensorFlow概述</a></li>
</ul>
<p class="caption"><span class="caption-text">基础</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../basic/installation.html">TensorFlow安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/basic.html">TensorFlow基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/models.html">TensorFlow模型建立与训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basic/tools.html">TensorFlow工具</a></li>
</ul>
<p class="caption"><span class="caption-text">部署</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="export.html">TensorFlow模型导出</a></li>
<li class="toctree-l1"><a class="reference internal" href="serving.html">TensorFlow Serving</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">TensorFlow Lite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">模型转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quantization">Quantization 模型转换</a></li>
<li class="toctree-l2"><a class="reference internal" href="#android">Android部署</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="javascript.html">TensorFlow in JavaScript</a></li>
</ul>
<p class="caption"><span class="caption-text">应用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../application/rl.html">TensorFlow智能物资调度</a></li>
<li class="toctree-l1"><a class="reference internal" href="../application/seq2seq-python.html">Tensorflow Python 闲聊机器人</a></li>
<li class="toctree-l1"><a class="reference internal" href="../application/seq2seq-javascript.html">Tensorflow JavaScript 闲聊对话模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../application/seq2seq-swift.html">TensorFlow Swift 闲聊机器人</a></li>
</ul>
<p class="caption"><span class="caption-text">附录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix/static.html">静态的TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/swift.html">TensorFlow in Swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/reuse.html">TensorFlow资源重用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/addons.html">TensorFlow库和扩展</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/optimization.html">TensorFlow性能优化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/training.html">TensorFlow大规模训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/custom_op.html">TensorFlow自定义运算操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/config.html">TensorFlow环境配置与管理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/recommended_books.html">参考资料与推荐阅读</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/terms.html">术语中英对照表</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">简单粗暴TensorFlow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>TensorFlow Lite</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/zh/deployment/lite.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tensorflow-lite">
<h1>TensorFlow Lite<a class="headerlink" href="#tensorflow-lite" title="永久链接至标题">¶</a></h1>
<div class="section" id="id1">
<h2>模型转换<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>由于移动设备空间和计算能力受限，使用TensorFlow训练好的模型，模型太大、运行效率比较低，不能直接在移动端部署。</p>
<p>故在移动端部署的时候，需要使用 <code class="docutils literal notranslate"><span class="pre">tflight_convert</span></code> 转化格式，其在通过pip安装TensorFlow时一起安装。 <code class="docutils literal notranslate"><span class="pre">tflight_convert</span></code> 会把原模型转换为FlatBuffer格式。</p>
<p>在终端执行如下命令:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tflight_convert</span> <span class="o">-</span><span class="n">h</span>
</pre></div>
</div>
<p>输出结果如下，即该命令的使用方法:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">tflite_convert</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="o">--</span><span class="n">output_file</span> <span class="n">OUTPUT_FILE</span>
                      <span class="p">(</span><span class="o">--</span><span class="n">graph_def_file</span> <span class="n">GRAPH_DEF_FILE</span> <span class="o">|</span> <span class="o">--</span><span class="n">saved_model_dir</span> <span class="n">SAVED_MODEL_DIR</span> <span class="o">|</span> <span class="o">--</span><span class="n">keras_model_file</span> <span class="n">KERAS_MODEL_FILE</span><span class="p">)</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">output_format</span> <span class="p">{</span><span class="n">TFLITE</span><span class="p">,</span><span class="n">GRAPHVIZ_DOT</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">inference_type</span> <span class="p">{</span><span class="n">FLOAT</span><span class="p">,</span><span class="n">QUANTIZED_UINT8</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">inference_input_type</span> <span class="p">{</span><span class="n">FLOAT</span><span class="p">,</span><span class="n">QUANTIZED_UINT8</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">input_arrays</span> <span class="n">INPUT_ARRAYS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">input_shapes</span> <span class="n">INPUT_SHAPES</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">output_arrays</span> <span class="n">OUTPUT_ARRAYS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">saved_model_tag_set</span> <span class="n">SAVED_MODEL_TAG_SET</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">saved_model_signature_key</span> <span class="n">SAVED_MODEL_SIGNATURE_KEY</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">std_dev_values</span> <span class="n">STD_DEV_VALUES</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">mean_values</span> <span class="n">MEAN_VALUES</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">default_ranges_min</span> <span class="n">DEFAULT_RANGES_MIN</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">default_ranges_max</span> <span class="n">DEFAULT_RANGES_MAX</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">post_training_quantize</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">drop_control_dependency</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">reorder_across_fake_quant</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">change_concat_input_ranges</span> <span class="p">{</span><span class="n">TRUE</span><span class="p">,</span><span class="n">FALSE</span><span class="p">}]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">allow_custom_ops</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">target_ops</span> <span class="n">TARGET_OPS</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">dump_graphviz_dir</span> <span class="n">DUMP_GRAPHVIZ_DIR</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">dump_graphviz_video</span><span class="p">]</span>
</pre></div>
</div>
<p>模型的导出：Keras Sequential save方法中产生的模型文件，可以使用如下命令处理：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tflite_convert --keras_model_file<span class="o">=</span>./mnist_cnn.h5 --output_file<span class="o">=</span>./mnist_cnn.tflite
</pre></div>
</div>
<p>到此，我们已经得到一个可以运行的TensorFlow Lite模型了，即 <code class="docutils literal notranslate"><span class="pre">mnist_cnn.tflite</span></code> 。</p>
<div class="admonition warning">
<p class="first admonition-title">警告</p>
<p class="last">这里只介绍了keras HDF5格式模型的转换，其他模型转换建议参考：<a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_examples.md">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_examples.md</a></p>
</div>
</div>
<div class="section" id="quantization">
<h2>Quantization 模型转换<a class="headerlink" href="#quantization" title="永久链接至标题">¶</a></h2>
<p>还有一种quantization的转化方法，这种转化命令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tflite_convert <span class="se">\</span>
  --output_file<span class="o">=</span>keras_mnist_quantized_uint8.tflite <span class="se">\</span>
  --keras_model_file<span class="o">=</span>mnist_cnn.h5 <span class="se">\</span>
  --inference_type<span class="o">=</span>QUANTIZED_UINT8 <span class="se">\</span>
  --mean_values<span class="o">=</span><span class="m">128</span> <span class="se">\</span>
  --std_dev_values<span class="o">=</span><span class="m">127</span> <span class="se">\</span>
  --default_ranges_min<span class="o">=</span><span class="m">0</span> <span class="se">\</span>
  --default_ranges_max<span class="o">=</span><span class="m">255</span> <span class="se">\</span>
  --input_arrays<span class="o">=</span>conv2d_1_input <span class="se">\</span>
  --output_arrays<span class="o">=</span>dense_2/Softmax
</pre></div>
</div>
<p>细心的读者肯定会问，上图中有很多参数是怎么来的呢？我们可以使用 <code class="docutils literal notranslate"><span class="pre">tflite_convert</span></code> 获得模型具体结构，命令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tflite_convert <span class="se">\</span>
  --output_file<span class="o">=</span>keras_mnist.dot <span class="se">\</span>
  --output_format<span class="o">=</span>GRAPHVIZ_DOT <span class="se">\</span>
  --keras_model_file<span class="o">=</span>mnist_cnn.h5
</pre></div>
</div>
<p>dot是一种graph description language，可以用graphz的dot命令转化为pdf或png等可视化图。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dot -Tpng -O keras_mnist.dot
</pre></div>
</div>
<p>这样就转化为一张图了，如下：</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../../_images/keras_mnist.dot.png"><img alt="../../_images/keras_mnist.dot.png" src="../../_images/keras_mnist.dot.png" style="width: 80%;" /></a>
</div>
<p>很明显的可以看到如下信息：</p>
<p>入口：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conv2d_1_input
Type: Float <span class="o">[</span><span class="m">1</span>×28×28×1<span class="o">]</span>
MinMax: <span class="o">[</span><span class="m">0</span>, <span class="m">255</span><span class="o">]</span>
</pre></div>
</div>
<p>出口：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>dense_2/Softmax
Type: Float <span class="o">[</span><span class="m">1</span>×10<span class="o">]</span>
</pre></div>
</div>
<p>因此，可以知道</p>
<p><code class="docutils literal notranslate"><span class="pre">--input_arrays</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">conv2d_1_input</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">--output_arrays</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">dense_2/Softmax</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">--default_ranges_min</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">--default_ranges_max</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">255</span></code></p>
<p>关于 <code class="docutils literal notranslate"><span class="pre">--mean_values</span></code> 和 <code class="docutils literal notranslate"><span class="pre">--std_dev_values</span></code> 的用途:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>QUANTIZED_UINT8的quantized模型期望的输入是[0,255], 需要有个跟原始的float类型输入有个对应关系。

mean_values和std_dev_values就是为了实现这个对应关系

mean_values对应float的float_min

std_dev_values对应255 / (float_max - float_min)
</pre></div>
</div>
<p>因此，可以知道</p>
<p><code class="docutils literal notranslate"><span class="pre">--mean_values</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">--std_dev_values</span></code> 就是 <code class="docutils literal notranslate"><span class="pre">1</span></code></p>
</div>
<div class="section" id="android">
<h2>Android部署<a class="headerlink" href="#android" title="永久链接至标题">¶</a></h2>
<p>现在开始在Android环境部署，对于国内的读者，需要先给Android Studio配置proxy，因为gradle编译环境需要获取相应的资源，请大家自行解决，这里不再赘述。</p>
<p><strong>配置app/build.gradle</strong></p>
<p>新建一个Android Project，打开 <code class="docutils literal notranslate"><span class="pre">app/build.gradle</span></code> 添加如下信息:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">android</span> <span class="p">{</span>
    <span class="n">aaptOptions</span> <span class="p">{</span>
        <span class="n">noCompress</span> <span class="s2">&quot;tflite&quot;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">repositories</span> <span class="p">{</span>
    <span class="n">maven</span> <span class="p">{</span>
        <span class="n">url</span> <span class="s1">&#39;https://google.bintray.com/tensorflow&#39;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">dependencies</span> <span class="p">{</span>
    <span class="n">implementation</span> <span class="s1">&#39;org.tensorflow:tensorflow-lite:+&#39;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其中，</p>
<ol class="arabic simple">
<li><code class="docutils literal notranslate"><span class="pre">aaptOptions</span></code> 设置tflite文件不压缩，确保后面tflite文件可以被Interpreter正确加载。</li>
<li><code class="docutils literal notranslate"><span class="pre">org.tensorflow:tensorflow-lite</span></code> 的最新版本号可以在这里查询 <a class="reference external" href="https://bintray.com/google/tensorflow/tensorflow-lite">https://bintray.com/google/tensorflow/tensorflow-lite</a></li>
</ol>
<p>设置好后，sync和build整个工程，如果build成功说明，配置成功。</p>
<p><strong>添加tflite文件到assets文件夹</strong></p>
<p>在app目录先新建assets目录，并将 <code class="docutils literal notranslate"><span class="pre">mnist_cnn.tflite</span></code> 文件保存到assets目录。重新编译apk，检查新编译出来的apk的assets文件夹是否有 <code class="docutils literal notranslate"><span class="pre">mnist_cnn.tflite</span></code> 文件。</p>
<p>使用apk analyzer查看新编译出来的apk，存在如下目录即编译打包成功:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">assets</span>
     <span class="o">|</span><span class="n">__mnist_cnn</span><span class="o">.</span><span class="n">tflite</span>
</pre></div>
</div>
<p><strong>加载模型</strong></p>
<p>使用如下函数将 <code class="docutils literal notranslate"><span class="pre">mnist_cnn.tflite</span></code> 文件加载到memory-map中，作为Interpreter实例化的输入</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">String</span> <span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="s">&quot;mnist_cnn.tflite&quot;</span><span class="o">;</span>

<span class="cm">/** Memory-map the model file in Assets. */</span>
<span class="kd">private</span> <span class="n">MappedByteBuffer</span> <span class="nf">loadModelFile</span><span class="o">(</span><span class="n">Activity</span> <span class="n">activity</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
    <span class="n">AssetFileDescriptor</span> <span class="n">fileDescriptor</span> <span class="o">=</span> <span class="n">activity</span><span class="o">.</span><span class="na">getAssets</span><span class="o">().</span><span class="na">openFd</span><span class="o">(</span><span class="n">MODEL_PATH</span><span class="o">);</span>
    <span class="n">FileInputStream</span> <span class="n">inputStream</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FileInputStream</span><span class="o">(</span><span class="n">fileDescriptor</span><span class="o">.</span><span class="na">getFileDescriptor</span><span class="o">());</span>
    <span class="n">FileChannel</span> <span class="n">fileChannel</span> <span class="o">=</span> <span class="n">inputStream</span><span class="o">.</span><span class="na">getChannel</span><span class="o">();</span>
    <span class="kt">long</span> <span class="n">startOffset</span> <span class="o">=</span> <span class="n">fileDescriptor</span><span class="o">.</span><span class="na">getStartOffset</span><span class="o">();</span>
    <span class="kt">long</span> <span class="n">declaredLength</span> <span class="o">=</span> <span class="n">fileDescriptor</span><span class="o">.</span><span class="na">getDeclaredLength</span><span class="o">();</span>
    <span class="k">return</span> <span class="n">fileChannel</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">FileChannel</span><span class="o">.</span><span class="na">MapMode</span><span class="o">.</span><span class="na">READ_ONLY</span><span class="o">,</span> <span class="n">startOffset</span><span class="o">,</span> <span class="n">declaredLength</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
</div>
<p>实例化Interpreter，其中this为当前acitivity</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">tflite</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Interpreter</span><span class="o">(</span><span class="n">loadModelFile</span><span class="o">(</span><span class="k">this</span><span class="o">));</span>
</pre></div>
</div>
<p><strong>运行输入</strong></p>
<p>我们使用mnist test测试集中的某张图片作为输入，mnist图像大小28*28，单像素。这样我们输入的数据需要设置成如下格式</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="cm">/** A ByteBuffer to hold image data, to be feed into Tensorflow Lite as inputs. */</span>
<span class="kd">private</span> <span class="n">ByteBuffer</span> <span class="n">imgData</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">DIM_BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>
<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">DIM_PIXEL_SIZE</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>

<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">DIM_IMG_WIDTH</span> <span class="o">=</span> <span class="mi">28</span><span class="o">;</span>
<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">int</span> <span class="n">DIM_IMG_HEIGHT</span> <span class="o">=</span> <span class="mi">28</span><span class="o">;</span>

<span class="kd">protected</span> <span class="kt">void</span> <span class="nf">onCreate</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">imgData</span> <span class="o">=</span> <span class="n">ByteBuffer</span><span class="o">.</span><span class="na">allocateDirect</span><span class="o">(</span>
        <span class="mi">4</span> <span class="o">*</span> <span class="n">DIM_BATCH_SIZE</span> <span class="o">*</span> <span class="n">DIM_IMG_WIDTH</span> <span class="o">*</span> <span class="n">DIM_IMG_HEIGHT</span> <span class="o">*</span> <span class="n">DIM_PIXEL_SIZE</span><span class="o">);</span>
    <span class="n">imgData</span><span class="o">.</span><span class="na">order</span><span class="o">(</span><span class="n">ByteOrder</span><span class="o">.</span><span class="na">nativeOrder</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
</div>
<p>将mnist图片转化成 <code class="docutils literal notranslate"><span class="pre">ByteBuffer</span></code> ，并保持到 <code class="docutils literal notranslate"><span class="pre">imgData</span></code> 中</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="cm">/** Preallocated buffers for storing image data in. */</span>
<span class="kd">private</span> <span class="kt">int</span><span class="o">[]</span> <span class="n">intValues</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">int</span><span class="o">[</span><span class="n">DIM_IMG_WIDTH</span> <span class="o">*</span> <span class="n">DIM_IMG_HEIGHT</span><span class="o">];</span>

<span class="cm">/** Writes Image data into a {@code ByteBuffer}. */</span>
<span class="kd">private</span> <span class="kt">void</span> <span class="nf">convertBitmapToByteBuffer</span><span class="o">(</span><span class="n">Bitmap</span> <span class="n">bitmap</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">(</span><span class="n">imgData</span> <span class="o">==</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span><span class="o">;</span>
    <span class="o">}</span>

    <span class="c1">// Rewinds this buffer. The position is set to zero and the mark is discarded.</span>
    <span class="n">imgData</span><span class="o">.</span><span class="na">rewind</span><span class="o">();</span>

    <span class="n">bitmap</span><span class="o">.</span><span class="na">getPixels</span><span class="o">(</span><span class="n">intValues</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">bitmap</span><span class="o">.</span><span class="na">getWidth</span><span class="o">(),</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">bitmap</span><span class="o">.</span><span class="na">getWidth</span><span class="o">(),</span> <span class="n">bitmap</span><span class="o">.</span><span class="na">getHeight</span><span class="o">());</span>
    <span class="c1">// Convert the image to floating point.</span>
    <span class="kt">int</span> <span class="n">pixel</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
    <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">DIM_IMG_WIDTH</span><span class="o">;</span> <span class="o">++</span><span class="n">i</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">DIM_IMG_HEIGHT</span><span class="o">;</span> <span class="o">++</span><span class="n">j</span><span class="o">)</span> <span class="o">{</span>
            <span class="kd">final</span> <span class="kt">int</span> <span class="n">val</span> <span class="o">=</span> <span class="n">intValues</span><span class="o">[</span><span class="n">pixel</span><span class="o">++];</span>
            <span class="n">imgData</span><span class="o">.</span><span class="na">putFloat</span><span class="o">(</span><span class="n">val</span><span class="o">);</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">convertBitmapToByteBuffer</span></code> 的输出即为模型运行的输入。</p>
<p><strong>运行输出</strong></p>
<p>定义一个1*10的多维数组，因为我们只有1个batch和10个label（TODO：need double check），具体代码如下</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="kd">private</span> <span class="kt">float</span><span class="o">[][]</span> <span class="n">labelProbArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">float</span><span class="o">[</span><span class="mi">1</span><span class="o">][</span><span class="mi">10</span><span class="o">];</span>
</pre></div>
</div>
<p>运行结束后，每个二级元素都是一个label的概率。</p>
<p><strong>运行及结果处理</strong></p>
<p>开始运行模型，具体代码如下</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">tflite</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">imgData</span><span class="o">,</span> <span class="n">labelProbArray</span><span class="o">);</span>
</pre></div>
</div>
<p>针对某个图片，运行后 <code class="docutils literal notranslate"><span class="pre">labelProbArray</span></code> 的内容如下，也就是各个label识别的概率</p>
<div class="highlight-java notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="mi">0</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">1</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">2</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">3</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">1.0</span>
<span class="n">index</span> <span class="mi">4</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">6</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">7</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">8</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
<span class="n">index</span> <span class="mi">9</span> <span class="n">prob</span> <span class="n">is</span> <span class="mf">0.0</span>
</pre></div>
</div>
<p>接下来，我们要做的就是根据对这些概率进行排序，找出Top的label并界面呈现给用户.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="javascript.html" class="btn btn-neutral float-right" title="TensorFlow in JavaScript" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="serving.html" class="btn btn-neutral float-left" title="TensorFlow Serving" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2019, Xihan Li（雪麒）

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>